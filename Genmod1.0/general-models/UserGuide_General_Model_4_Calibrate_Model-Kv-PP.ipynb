{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create a general MODFLOW model from the NHDPlus dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a grid-search approach to finding hydraulic conductivities that result in heads that seem reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project specific variables are imported in the model_spec.py and gen_mod_dict.py files that must be included in the notebook directory. The first first includes pathnames to data sources that will be different for each user. The second file includes a dictionary of model-specific information such as  cell size, default hydraulic parameter values, and scenario defintion (e.g. include bedrock, number of layers, etc.). There are examples in the repository. Run the following cells up to the \"Run to here\" cell to get a pull-down menu of models in the model_dict. Then, without re-running that cell, run all the remaining cells.  Re-running the following cell would re-set the model to the first one in the list, which you probably don't want. If you use the notebook option to run all cells below, it runs the cell you're in, so if you use that option, move to the next cell (below the pull-down menu of models) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "from model_specs import *\n",
    "from gen_mod_dict import *\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import flopy as fp\n",
    "import pandas as pd\n",
    "# import ipyparallel as ipp\n",
    "# from model_specs import *\n",
    "# from gen_mod_dict import *\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is a template for making this notebook into a batch script. To do so, save this notebook as a .py file and edit it as follows. Comment out all the notebook-specific commands (drop-down menu stuff and commands preceded by %). Indent everything below the next cell twice so that it falls within the 'for' loop and the 'try' statement. Move the 'except' statement to the end of the script. Comment out lines in the cell after 'Preliminary stuff' so that the model is selected in the 'for' loop from gen_mod_dict. You can leave the print statement in that cell uncommented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model_dict.items():\n",
    "    md = key\n",
    "    ms = model_dict[md]\n",
    "    print('trying {}'.format(md))\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(model_dict.keys())\n",
    "models.sort()\n",
    "model_area = Dropdown(\n",
    "    options=models,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to here to initiate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time using this notebook in this session (before restarting the notebook), run the cells up to this point. Then select your model from the dropdown list above. Move your cursor to this cell and use the toolbar menu Cell --> Run All Below.  After the first time, if you want to run another model, select your model and start running from this cell--you don't need to re-run the cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = model_area.value\n",
    "ms = model_dict[md]\n",
    "print('The model being processed is {}\\n'.format(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set observation weight here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy model to be calibrated (parent model) to new directory. Define the weight, which is used after all the models are run to find the best set of parameters by weighting the error rates. It is specified here so it can be used in the directory name. Weights > 1 result in fewer dry drains and more cells with heads above land surface. That tends to mean lower hydraulic conductivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_wt = 1.\n",
    "\n",
    "geo_ws = os.path.join(proj_dir, ms['ws'])\n",
    "parent_ws = os.path.join(geo_ws, scenario_dir)\n",
    "dir_name = '{}_cal_wt_{:4.2f}'.format(scenario_dir, hydro_wt)\n",
    "model_ws = os.path.join(geo_ws, dir_name)\n",
    "\n",
    "if os.path.exists(parent_ws):\n",
    "    if os.path.exists(model_ws):\n",
    "        shutil.rmtree(model_ws)\n",
    "        shutil.copytree(parent_ws, model_ws)\n",
    "    else:\n",
    "        shutil.copytree(parent_ws, model_ws)\n",
    "else:\n",
    "    print('Parent model does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'mf.bat')\n",
    "with open(dst, 'w') as f:\n",
    "    line = '{} {}.nam'.format(mfpth, md)\n",
    "    f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing model and some packages needed for parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_file = '{}.nam'.format(md)\n",
    "mf = fp.modflow.Modflow.load(nam_file, version='mfnwt', exe_name=mfpth, \n",
    "                             verbose=False, model_ws=model_ws, load_only=None)\n",
    "\n",
    "bas = mf.get_package('BAS6')\n",
    "dis = mf.get_package('DIS')\n",
    "upw = mf.get_package('UPW')\n",
    "oc = mf.get_package('OC')\n",
    "#head_file_pth = os.path.join(model_ws, oc.file_name[1])\n",
    "head_file_pth = os.path.join(model_ws, os.path.splitext(oc.file_name[0])[0] + '.hds')\n",
    "\n",
    "ibound = bas.ibound\n",
    "botm = dis.getbotm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-write nwt package with head tol = 0.001 for quicker convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwt = mf.get_package('NWT')\n",
    "nwt.headtol = 0.001\n",
    "mf.external_path = 'arrays'\n",
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read model_grid data frame created in notebook 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(geo_ws, 'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file, na_values=[hnoflo, hdry])\n",
    "\n",
    "obs_type = model_grid.obs_type\n",
    "land_surface = model_grid.top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the zone array from the compressed zone file created in notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_file = os.path.join(model_ws, 'zone_array.npz')\n",
    "zones = np.load(zone_file)\n",
    "zones = zones['zone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a few space-saving functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_par_grid(k_ar_f, k_ar_c, k_ar_b, k_ar_va):\n",
    "    Kf, Kc, Kb, KVa = np.meshgrid( k_ar_f, k_ar_c, k_ar_b, k_ar_va )\n",
    "    Kf, Kc, Kb, KVa = Kf.ravel(), Kc.ravel(), Kb.ravel(), KVa.ravel()\n",
    "    index = Kf < Kc\n",
    "    num_par = index.sum()\n",
    "    par_grid = np.zeros((num_par, 11))\n",
    "    par_grid[:, 0:4] = np.array((Kf[index], Kc[index], Kb[index], KVa[index])).T\n",
    "    return par_grid\n",
    "\n",
    "def new_k_arr(k, par_ar, num_k):\n",
    "    index = np.arange(new_num_k)[par_ar == k]\n",
    "    lo = par_ar[index - 1]\n",
    "    hi = par_ar[index + 1]\n",
    "    return np.logspace(np.log10(lo), np.log10(hi), num_k)\n",
    "\n",
    "def make_par_df(par_grid, hydro_wt):\n",
    "    par_df = pd.DataFrame.from_records(par_grid, columns=['Kf', 'Kc', 'Kb', 'vani', 'hydro', \n",
    "                                                          'topo', 'sse', 'p5', 'p10', 'p20', 'Best'])\n",
    "    par_df.dropna(axis='rows', inplace=True)\n",
    "    par_df['diff_error'] = np.abs((par_df.hydro * hydro_wt) - par_df.topo)\n",
    "    par_df['sum_error'] = par_df.hydro + par_df.topo\n",
    "\n",
    "    # these lines implement the alternative algorithms \n",
    "#         tol = 0.20\n",
    "#         ptol = 0.10    \n",
    "#         reasonable = par_df[par_df.p10 < ptol]\n",
    "#         h_min = par_df.loc[reasonable.hydro.argmin(), 'topo']\n",
    "#         index = (par_df['topo'] <= (h_min * (1 + tol))) & (par_df['topo'] > (h_min * (1 - tol)))\n",
    "#         best = par_df.loc[index, 'hydro'].argmin()\n",
    "#         par_df.loc[best, 'Best'] = True\n",
    "\n",
    "    # this line chooses parameters where fraction hydro errors ~ fraction topo errors\n",
    "#     par_df.loc[par_df.diff_error.argmin(), 'Best'] = True\n",
    "    \n",
    "    # this code chooses the lowest difference error from the lowest 10% sum error.\n",
    "    # the 'name' attribute grabs the line number (Pandas index)\n",
    "    target_magnitude = par_df.sum_error.min() * 1.10\n",
    "    par_df.loc[par_df.sum_error <= target_magnitude, 'Best'] = 'low_sum'\n",
    "    index = par_df.loc[par_df.Best == 'low_sum', :].diff_error.argmin()\n",
    "    par_df.loc[index, 'Best'] = 'low_diff'\n",
    "    return par_df\n",
    "        \n",
    "def run_model1(k_):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import flopy as fp\n",
    "    import subprocess as sp\n",
    "    \n",
    "    def calc_error(top, head, obs_type):\n",
    "    # an offset of err_tol is used to eliminate counting heads that\n",
    "    # are within err_tol m of their target as errors.\n",
    "        if test_model(mf_lst_pth):\n",
    "            # count topo and hydro errors\n",
    "            t = top < (head - err_tol)\n",
    "            h = top > (head + err_tol)\n",
    "\n",
    "            tmp_df = pd.DataFrame({'head':head, 'ot':obs_type, 't':t, 'h':h})\n",
    "\n",
    "            tmp = tmp_df.groupby('ot').sum()\n",
    "            h_e_ = tmp.loc['hydro', 'h']\n",
    "            t_e_ = tmp.loc['topo', 't']\n",
    "            result = np.array([h_e_, t_e_])\n",
    "        else:\n",
    "            result = np.array([np.nan, np.nan])\n",
    "        return result\n",
    "   \n",
    "    def write_K(K):\n",
    "        nl = K.shape[0]\n",
    "        for i in range(nl):\n",
    "            name = os.path.join(model_ws, 'arrays', 'hk_layer_{}.ref'.format(i + 1))\n",
    "            np.savetxt(name, K[i, :, :], fmt='%15.6E', delimiter='')  \n",
    "\n",
    "    def write_V(V):\n",
    "        nl = V.shape[0]\n",
    "        for i in range(nl):\n",
    "            name = os.path.join(model_ws, 'arrays', 'vani_layer_{}.ref'.format(i + 1))\n",
    "            np.savetxt(name, V[i, :, :], fmt='%15.6E', delimiter='')  \n",
    "\n",
    "# prepend wine to modflow executable if 'window' not in platform.platform().lower()\n",
    "\n",
    "    def solve_heads(mfpth):\n",
    "        beg = os.getcwd()\n",
    "        os.chdir(model_ws)\n",
    "        sp.call([mfpth, mf_nam])\n",
    "        os.chdir(beg)\n",
    "        hedf = fp.utils.HeadFile(head_file_pth)\n",
    "        heads = hedf.get_data()\n",
    "        # eliminate unrealistic heads that sometimes occur in isolated cells\n",
    "        heads[heads > 1.E+29] = np.nan\n",
    "        return heads\n",
    "\n",
    "    def get_obs(heads):\n",
    "        # make a 2D array of head in the highest active cell\n",
    "        heads[heads == bas.hnoflo] = np.nan\n",
    "        heads[heads == upw.hdry] = np.nan\n",
    "        hin = np.argmax(np.isfinite(heads), axis=0)\n",
    "        row, col = np.indices((hin.shape))\n",
    "        h = heads[hin, row, col]\n",
    "        return h.ravel()\n",
    "\n",
    "    def test_model(mf_lst_pth, bad_run=10.0):\n",
    "        # check that the model has a reasonable mass balance\n",
    "        with open(mf_lst_pth) as fn:\n",
    "            tmp = fn.readlines()\n",
    "        line = [line.split() for line in tmp if 'PERCENT DISCREPANCY =' in line]\n",
    "        perc_disc = float(line[0][3])\n",
    "        if perc_disc > bad_run:\n",
    "            print('Percent discrepancy for this run is bad and equals {}'.format(perc_disc))\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    K = K_from_kvec.copy()\n",
    "    K[zones == 0] = k_[0]\n",
    "    K[zones == 1] = k_[1]\n",
    "    K[zones == 3] = k_[2]\n",
    "    write_K(K)\n",
    "\n",
    "    V = np.ones(K.shape) * k_[3]\n",
    "    write_V(V)\n",
    "\n",
    "    heads = solve_heads(mfpth)\n",
    "    yhat = get_obs(heads)\n",
    "\n",
    "    e_ = calc_error(land_surface, yhat, obs_type)\n",
    "\n",
    "    e = land_surface - yhat\n",
    "    ew = e * w\n",
    "    ew.dropna(inplace=True)\n",
    "    sse = (ew.T).dot(ew)\n",
    "    \n",
    "    # write the array to text for return\n",
    "\n",
    "    k_[4:6] = e_\n",
    "    k_[6] = sse\n",
    "    k_[7] = np.float32((e) < -5.).sum() / num_cells\n",
    "    k_[8] = np.float32((e) < -10.).sum() / num_cells\n",
    "    k_[9] = np.float32((e) < -20.).sum() / num_cells\n",
    "\n",
    "    k_[4] = k_[4] / num_hydro\n",
    "    k_[5] = k_[5] / num_topo\n",
    "    k_[6] = k_[6] / num_cells    \n",
    "    return k_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace entries from the default K_dict with the model specific K values from model_dict if they exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in K_dict.items():\n",
    "    if key in ms.keys():\n",
    "        K_dict[key] = ms[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a dictionary to map K values to their zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvec = {0 : K_dict['K_fine'], 1 : K_dict['K_coarse'], 2 : K_dict['K_lakes'], 3 : K_dict['K_bedrock']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a K array using the default values from gen_mod_dict. A copy will be created in each iteration and the new K values substitued by zone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_from_kvec = np.zeros_like(zones, dtype=np.float32)\n",
    "for i, k in kvec.items():\n",
    "    K_from_kvec[zones == i] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights (w) aren't used (in this version of the notebook) to select the best parameter sets.  Weights are only used to calculate the weighted sum of square residuals. SSWR is included for possible future use. Weights are the distance from a cell to the nearest drain divided by the maximum distance between a cell and a drain. The values range 0 to 1. 1 occurs at a drain; 0 occurs at the farthest point. The purpose is to give more weight to errors near a drain where we are most confident about the water level. \n",
    "\n",
    "The value hydro_weights ** is ** used, but by default is set to 1.  It is used to weight relative errors between hydro and topo errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model_grid.dist2str / model_grid.dist2str.max()\n",
    "w = 1 - w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of each type of observation are used later to normalize error counts, resulting in fractional error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hydro = obs_type.value_counts()['hydro']\n",
    "num_topo = obs_type.value_counts()['topo']\n",
    "num_cells = num_hydro + num_topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model parameter grid for order-of-magnitude estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of parameter values to try. The number of K values specified by num_k are created between p_min and p_max on a log scale. p_min and p_max are the base-10 exponents of K values. For example, np.logspace(-1, 2, 4) creates K values (0.1, 1.0, 10., 100.). All possible pairs of values are generated, then combinations where Kc < Kf are eliminated as being unrealistic. The K values can be created in any alternative way desired as long as the shape of par_grid is unchanged and the position (column) of the K values is unchanged. This procedure is repeated later in the notebook for a smaller range centered on the preliminary 'best' values.\n",
    "\n",
    "* Kf is K fine\n",
    "* Kc is K coarse\n",
    "* Kb is K bedrock\n",
    "* vani is vertical anisotropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_k = 4\n",
    "new_num_k = num_k * 3 - 1\n",
    "par_ar = np.logspace(-2, 3, new_num_k)\n",
    "\n",
    "k_ar_f = par_ar[2 : -2 : 2]\n",
    "k_ar_c = par_ar[2 : -2 : 2]\n",
    "k_ar_b = par_ar[2 : -2 : 2] \n",
    "k_ar_va = par_ar[4 : -2 : 2]\n",
    "# k_ar_f = np.array((1., 10., 100.0))\n",
    "# k_ar_c = np.array((100.))\n",
    "# k_ar_b = np.array((0.1))\n",
    "# k_ar_va = np.array((10.))\n",
    "\n",
    "mag_par_grid = make_par_grid(k_ar_f, k_ar_c, k_ar_b, k_ar_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through mag_par_grid and run the model for each set of parameters (using ```map```). Calculate different types of error and store them in mag_par_grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-write run_model so it is self-contained (internal imports, variables passed explicitly) the same way it would work in ipp. the function do_it should be similar to view.apply_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_nam = mf.namefile\n",
    "mf_lst_pth = mf.lst.fn_path\n",
    "mf_nam = mf.namefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = [run_model1(item) for item in mag_par_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list(map(run_model1, mag_par_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('temp.txt', mag_par_grid)\n",
    "# run_num = sys.argv[1]\n",
    "# mag_par_grid = np.loadtxt('temp.txt')\n",
    "# results = runmodel1(mag_par_grid[run_num])\n",
    "# # pull results together\n",
    "# return_file = 'results_{0}.dat'.format(run_num)\n",
    "# with open(return_file, 'w') as ofp:\n",
    "#     [ofp.write(i, '\\n') for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc = ipp.Client()\n",
    "# # lv = rc.load_balanced_view()\n",
    "# dv = rc.direct_view()\n",
    "# rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv.push({'K_from_kvec':K_from_kvec, 'zones':zones, 'land_surface':land_surface, \n",
    "#          'obs_type':obs_type, 'num_cells':num_cells, 'num_hydro':num_hydro, \n",
    "#          'num_topo':num_topo, 'model_ws':model_ws, 'mf_lst_pth':mf.lst.fn_path,\n",
    "#         'mfpth':mfpth, 'mf_nam':mf.namefile , 'head_file_pth':head_file_pth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar = dv.map_sync(run_model1, mag_par_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async_results = []\n",
    "# for run, k_ in enumerate(mag_par_grid): \n",
    "#     ar = lv.apply_async(run_model, k_, K_from_kvec, zones, land_surface, \n",
    "#                           obs_type, num_cells, num_hydro, num_topo)\n",
    "#     async_results.append(ar)\n",
    "# rc.wait(async_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert par_grid to a data frame for easier manipulation.\n",
    "\n",
    "The relative weight for hydro and topo observations is set near the top of the notebook. A value of 1 means that the best parameter set will result in the same fraction of hydro errors as topo errors. Weights greater than 1 favor higher K's. The 'root' variable is the weighted sum of topo and hydro errors.\n",
    "\n",
    "Any combination of error measures can be used for model calibration. Here are two possibilities:\n",
    "\n",
    "* Choose parameters that make the number of topo and hydro errors close\n",
    "* Comment out last line to get\n",
    "    * eliminate parameters where > 10% of cells have head > 10m above land surface AND\n",
    "    * keep parameters within that group that are within 20% of the minimum number of hydro errors AND\n",
    "    * choose parameters from within that group with the lowest topo error\n",
    "    \n",
    "There may be alternative parameters sets that are almost as good, compared to these criteria. Alternative parameter sets should also be investigated. Check the par.csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_par_df = make_par_df(mag_par_grid, hydro_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model parameter grid for refined estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat model runs for parameters sets centered on the 'best' values from above. Expand the range using a log scale around the best value and follow the procedure as above. \n",
    "* Expand the range used above by one order of magnitude lower and higher\n",
    "* Create intermediate log-scale values\n",
    "* Use the intermediate values below (lo) and above (hi) the 'best' \n",
    "* Make new num_k values from lo to hi, centered on the 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = mag_par_df.loc[mag_par_df['Best'] == 'low_diff', ['Kf', 'Kc', 'Kb', 'vani']].values[0]\n",
    "\n",
    "k_ar_f = new_k_arr(k_[0], par_ar, num_k)\n",
    "k_ar_c = new_k_arr(k_[1], par_ar, num_k) \n",
    "k_ar_b = new_k_arr(k_[2], par_ar, num_k) \n",
    "\n",
    "if k_[3] == 1:\n",
    "    k_ar_va = new_k_arr(k_[3], par_ar, 4)[-1:]\n",
    "if k_[3] == 10:\n",
    "    k_ar_va = new_k_arr(k_[3], par_ar, 2)\n",
    "if k_[3] == 100:\n",
    "    k_ar_va = new_k_arr(k_[3], par_ar, 2)\n",
    "\n",
    "ref_par_grid = make_par_grid(k_ar_f, k_ar_c, k_ar_b, k_ar_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for all the parameter sets in par_grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New line below limits the amount of vertical anisotropy to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_par_grid = ref_par_grid[ref_par_grid[:,3] <= 100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_par_grid = run_grid(ref_par_grid)\n",
    "# make this data2\n",
    "r = list(map(run_model1, ref_par_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the two data frames (from the order-of-magnitude and the centered parameter grids). Save the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par_grid = np.concatenate((mag_par_grid, ref_par_grid))\n",
    "# par_df = make_par_df(par_grid, hydro_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.extend(r)\n",
    "par_df = make_par_df(m, hydro_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'par.csv')\n",
    "par_df.to_csv(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is run one final time with the 'best' parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First re-set headtol to the original value of 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwt = mf.get_package('NWT')\n",
    "nwt.headtol = 0.0001\n",
    "mf.external_path = 'arrays'\n",
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = par_df.loc[par_df['Best'] == 'low_diff', :'Best'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model1(k_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hy = par_df.loc[par_df.Best == 'low_diff', 'hydro']\n",
    "f_to = par_df.loc[par_df.Best == 'low_diff', 'topo']\n",
    "\n",
    "K = K_from_kvec.copy()\n",
    "K[zones == 0] = k_[0]\n",
    "K[zones == 1] = k_[1]\n",
    "K[zones == 3] = k_[2]\n",
    "\n",
    "hedf = fp.utils.HeadFile(head_file_pth)\n",
    "heads = hedf.get_data()\n",
    "heads[heads == bas.hnoflo] = np.nan\n",
    "heads[heads == upw.hdry] = np.nan\n",
    "hin = np.argmax(np.isfinite(heads), axis=0)\n",
    "row, col = np.indices((hin.shape))\n",
    "h = heads[hin, row, col]\n",
    "yhat = h.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imask = bas.ibound[:,:,:]\n",
    "\n",
    "def ma2(data2D):\n",
    "    return np.ma.MaskedArray(data2D, mask=(imask[0,:,:] == 0))\n",
    "\n",
    "def ma3(data3D):\n",
    "    return np.ma.MaskedArray(data3D, mask=(imask == 0))\n",
    "\n",
    "row_to_plot = int(dis.nrow / 2)\n",
    "xplot = np.linspace( L / 2, dis.ncol * L - L / 2, dis.ncol)\n",
    "\n",
    "mKh = ma3(K)\n",
    "mtop = ma2(land_surface.reshape(dis.nrow, dis.ncol))\n",
    "mbot = ma3(botm)\n",
    "mbed = ma2(model_grid.bedrock_el.reshape(dis.nrow, dis.ncol))\n",
    "water_table_ma = ma2(yhat.reshape(dis.nrow, dis.ncol))\n",
    "colors = ['green', 'red', 'gray']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "ax1.plot(xplot, mtop[row_to_plot, ], label='land surface', color='black', lw=0.5)\n",
    "ax1.plot(xplot, water_table_ma[row_to_plot, ], label='water table (cal)', color='blue', lw=1.)\n",
    "ax1.fill_between(xplot, mtop[row_to_plot, ], mbot[0, row_to_plot, :], alpha=0.25, \n",
    "                 color='blue', label='layer 1', lw=0.75)\n",
    "for lay in range(dis.nlay - 1):\n",
    "    label = 'layer {}'.format(lay+2)\n",
    "    ax1.fill_between(xplot, mbot[lay, row_to_plot, :], mbot[lay+1, row_to_plot, :], label=label, \n",
    "                    color=colors[lay], alpha=0.250, lw=0.75)\n",
    "ax1.plot(xplot, mbed[row_to_plot, :], label='bedrock (Soller)', color='red', linestyle='dotted', lw=1.5)\n",
    "ax1.plot(xplot, mbot[-1, row_to_plot, :], color='black', linestyle='solid', lw=0.5)\n",
    "ax1.legend(loc=0, frameon=False, fontsize=10, ncol=3)#, bbox_to_anchor=(1.0, 0.5))\n",
    "ax1.set_ylabel('Altitude in meters')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_title('Adjusted section along row {}, {} model, weight {:0.1f}\\nK fine = {:0.1f}  K coarse = {:0.1f}\\\n",
    " K bedrock = {:0.1f} Van = {:0.0f}\\nFraction dry drains {:0.2f} Fraction flooded cells {:0.2f}'.format(row_to_plot, \\\n",
    " md, hydro_wt, k_[0], k_[1], k_[2], k_[3], f_hy.values[0], f_to.values[0]))\n",
    "\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax2.fill_between(xplot, 0, mKh[0, row_to_plot, :], alpha=0.25, color='blue', \n",
    "                 label='layer 1', lw=0.75, step='mid')\n",
    "ax2.set_xlabel('Distance in meters')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('Hydraulic conductivity\\n in layer 1, in meters / day')\n",
    "\n",
    "line = '{}_{}_xs_cal.png'.format(md, scenario_dir)\n",
    "fig_name = os.path.join(model_ws, line)\n",
    "plt.savefig(fig_name)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cross-section and 2D maps are made showing where errors occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top, head, obs_type = land_surface, yhat, obs_type\n",
    "\n",
    "t = top < (head - err_tol)\n",
    "h = top > (head + err_tol)\n",
    "\n",
    "mt = np.ma.MaskedArray(t.reshape(dis.nrow, dis.ncol), obs_type != 'topo')\n",
    "mh = np.ma.MaskedArray(h.reshape(dis.nrow, dis.ncol), obs_type != 'hydro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "cmap = colors.ListedColormap(['0.50', 'red'])\n",
    "cmap2 = colors.ListedColormap(['blue'])\n",
    "\n",
    "back = np.ma.MaskedArray(ibound[0,:,:], ibound[0,:,:] == 0)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(back, cmap=cmap2, alpha=0.2)\n",
    "im0 = ax[0].imshow(mh, cmap=cmap, interpolation='None')\n",
    "ax[0].axhline(row_to_plot)\n",
    "# fig.colorbar(im0, ax=ax[0])\n",
    "ax[1].imshow(back, cmap=cmap2, alpha=0.2)\n",
    "im1 = ax[1].imshow(mt, cmap=cmap, interpolation='None')\n",
    "ax[1].axhline(row_to_plot)\n",
    "# fig.colorbar(im1, ax=ax[1])\n",
    "# fig.suptitle('Adjusted model errors (in red) along row {}, {} model, weight {:0.1f}\\nK fine = {:0.1f}  K coarse = {:0.1f}\\\n",
    "#  K bedrock = {:0.1f}\\nFraction dry drains {:0.2f} Fraction flooded cells {:0.2f}'.format(row_to_plot, \\\n",
    "#  md, hydro_wt, k_[0], k_[1], k_[2], f_hy.values[0], f_to.values[0]))\n",
    "\n",
    "fig.suptitle('Adjusted model errors (in red), {} model, weight {:0.1f}\\nK fine = {:0.1f}  K coarse = {:0.1f}\\\n",
    " K bedrock = {:0.1f} Van = {:0.0f}\\nFraction dry drains {:0.2f} Fraction flooded cells {:0.2f}'.format( \\\n",
    " md, hydro_wt, k_[0], k_[1], k_[2], k_[3], f_hy.values[0], f_to.values[0]))\n",
    "\n",
    "\n",
    "# fig.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "#                       wspace=None, hspace=None)\n",
    "\n",
    "fig.set_size_inches(6, 6)\n",
    "\n",
    "line = '{}_{}_error_map_cal.png'.format(md, scenario_dir)\n",
    "fig_name = os.path.join(model_ws, line)\n",
    "plt.savefig(fig_name)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "90f9d0893d12498c9243429b3e2bd94d": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
