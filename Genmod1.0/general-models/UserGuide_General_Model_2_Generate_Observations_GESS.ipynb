{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create a general MODFLOW model from the NHDPlus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "import pandas as pd\n",
    "import random\n",
    "import gdal\n",
    "from model_specs import *\n",
    "from gen_mod_dict import *\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model_dict.items():\n",
    "    md = key\n",
    "    ms = model_dict[md]\n",
    "    print('trying {}'.format(md))\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project specific variables are imported in the model_spec.py and gen_mod_dict.py files that must be included in the notebook directory. The first first includes pathnames to data sources that will be different for each user. The second file includes a dictionary of model-specific information such as  cell size, default hydraulic parameter values, and scenario defintion (e.g. include bedrock, number of layers, etc.). There are examples in the repository. Run the following cell to get a pull-down menu of models in the model_dict. Then, without re-running that cell, run all the remaining cells.  Re-running the following cell would re-set the model to the first one in the list, which you probably don't want. If you use the notebook option to run all cells below, it runs the cell you're in, so if you use that option, move to the next cell (below the pull-down menu of models) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(model_dict.keys())\n",
    "models.sort()\n",
    "model_area = Dropdown(\n",
    "    options=models,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = model_area.value\n",
    "ms = model_dict[md]\n",
    "print('The model being processed is {}'.format(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read model_grid.csv file that was created using first general model notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws = os.path.join(proj_dir, ms['ws'])\n",
    "model_file = os.path.join(model_ws, 'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file, na_values=[hnoflo])\n",
    "if 'obs_grp' in model_grid.columns:\n",
    "    model_grid.drop('obs_grp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get NROW, NCOL from model_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NROW = model_grid.row.max() + 1\n",
    "NCOL = model_grid.col.max() + 1\n",
    "num_cells = NROW * NCOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell makes a new column that contains the percent coarse material (which comes from 'is_coarse' in model_grid.csv') in the local neighborhood of each cell. The user can change the size of the neighborhood, which is a square blcok of cells centered on each cell as it moves, by changing the variable hood_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_coarse = np.zeros(( NROW, NCOL ), dtype=np.float32)\n",
    "\n",
    "gess = model_grid.gess_poly.values.reshape( NROW, NCOL )\n",
    "\n",
    "is_coarse[gess == 0] = 0\n",
    "is_coarse[gess == 1] = 1\n",
    "\n",
    "# use this number to get broader dist of pct_coarse\n",
    "# this might allow quantiles where otherwise none are possible\n",
    "# this variable is not stored for the next step--only used here for quantiles\n",
    "hood_size = 5\n",
    "footprint = np.ones((hood_size, hood_size)) / hood_size**2\n",
    "temp = nd.correlate(is_coarse, footprint,)\n",
    "model_grid['pct_coarse'] = temp.ravel()\n",
    "model_grid.pct_coarse.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select 'hydro' obs from model_grid\n",
    "* Put the integer that represents unique reaches into the index\n",
    "* Groupby the reach integer so that all the cells that belong to a reach are grouped together\n",
    "* Add labels to identify the quantiles of the median elevation of all the cells for each reach\n",
    "* Groupby by those quantiles so that all the cells that belong to each quantile are grouped together\n",
    "* Loop through the rows from the original dataframe and select the rows that belong to the elevation quantile group\n",
    "* Label each group as they're being looped through and append them for each observation\n",
    "* The commented-out statement could be used to randomly sample from each group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make additional obs using drain observation in MODFLOW (should be > 0)\n",
    "# pull out drain flows from budget package for first order\n",
    "# also summarize flow at gages\n",
    "sel = pd.DataFrame(model_grid[model_grid.obs_type == 'hydro'])\n",
    "sel.set_index(sel.reach_int, drop=False, inplace=True)\n",
    "\n",
    "num_of_samples = 10\n",
    "num_of_obs = 5\n",
    "\n",
    "o1 = sel.groupby(['reach_int']).median()\n",
    "o1['top_quant'], rbins = pd.qcut(o1.top, num_of_obs, retbins=True, labels=False)\n",
    "\n",
    "temp = o1.groupby(['top_quant'])\n",
    "stream_obs = pd.DataFrame()\n",
    "for grp, item in temp:\n",
    "    obs = pd.DataFrame(sel.loc[item.index])\n",
    "    obs['obs_grp'] = 'strm_el{}'.format(grp)\n",
    "    obs['obs_grp_int'] = grp + 1\n",
    "    stream_obs = pd.concat([stream_obs, obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: possible enhancement is to add within-cell percent coarse\n",
    "num_of_obs = 3\n",
    "\n",
    "is_topo = model_grid.obs_type == 'topo'\n",
    "\n",
    "try:\n",
    "    model_grid.loc[is_topo, 'top_quant'] = pd.qcut(model_grid.top, num_of_obs, labels=[1, 2, 3])\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    model_grid.loc[is_topo, 'coarse_grp'] = pd.cut(model_grid.pct_coarse, [0.0, 0.1, 0.9, 1.0], \n",
    "                                         include_lowest=True, labels=[1, 2, 3])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    mini_mohp = model_grid.dist2str / model_grid.dist2str.max()\n",
    "    model_grid.loc[is_topo, 'hypo_quant'] = pd.cut(mini_mohp, [0.0, 0.3333, 0.6666, 1.0], \n",
    "                                                   include_lowest=True, labels=[1, 2, 3])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell saves one of the individual quantiles or quantile-based observation groups as tiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_grid.pct_coarse.values.reshape(NROW,NCOL)\n",
    "\n",
    "src_pth = os.path.join(model_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'pct_coarse.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(-9999)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_grid.coarse_grp.values.reshape(NROW,NCOL)\n",
    "\n",
    "src_pth = os.path.join(model_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'coarse_grp.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(255)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_grid.hypo_quant.values.reshape(NROW,NCOL)\n",
    "\n",
    "src_pth = os.path.join(model_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'hypo_quant.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(255)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_grid.top_quant.values.reshape(NROW,NCOL)\n",
    "\n",
    "src_pth = os.path.join(model_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'top_quant.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(255)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((num_cells))\n",
    "blank[stream_obs.node_num.values] = stream_obs.obs_grp_int\n",
    "data = blank.reshape((NROW,NCOL))\n",
    "\n",
    "src_pth = os.path.join(model_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'stream_obs.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(0)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "ce88a795094849f0b07c629442c9def0": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
